{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import math\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, optimizers\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_csv(path):\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = math.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(956868, 239217)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = './data/train.csv'\n",
    "test_path = './data/test.csv'\n",
    "\n",
    "X_train, X_test = read_from_csv(train_path, ), read_from_csv(test_path)\n",
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = pd.DataFrame(X_train['duration']), pd.DataFrame(X_test['duration'])\n",
    "\n",
    "X_train.drop(columns=['duration'], inplace=True)\n",
    "X_test.drop(columns=['duration'], inplace=True)\n",
    "\n",
    "# drop the datetime type columns\n",
    "X_train.drop(columns=['tpep_dropoff_datetime', 'tpep_pickup_datetime'], inplace=True)\n",
    "X_test.drop(columns=['tpep_dropoff_datetime', 'tpep_pickup_datetime'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LinearRegression().fit(X_train, y_train)\n",
    "model_ridge = Ridge().fit(X_train, y_train)\n",
    "model_lasso = Lasso().fit(X_train, y_train)\n",
    "model_elasticnet = ElasticNet().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss for Linear Regression: 1.7834776609741771\n",
      "Train Loss for Ridge Regression: 1.783531230312074\n",
      "Train Loss for Lasso Regression: 2.5064942394275147\n",
      "Train Loss for Elastic_Net Regression: 2.898159245422226\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "y_pred1 = model_lr.predict(X_train)\n",
    "y_pred2 = model_ridge.predict(X_train)\n",
    "y_pred3 = model_lasso.predict(X_train)\n",
    "y_pred4 = model_elasticnet.predict(X_train)\n",
    "\n",
    "train_loss1 = get_rmse(y_train, y_pred1)\n",
    "train_loss2 = get_rmse(y_train, y_pred2)\n",
    "train_loss3 = get_rmse(y_train, y_pred3)\n",
    "train_loss4 = get_rmse(y_train, y_pred4)\n",
    "\n",
    "print(\"Train Loss for Linear Regression: {}\".format(train_loss1))\n",
    "print(\"Train Loss for Ridge Regression: {}\".format(train_loss2))\n",
    "print(\"Train Loss for Lasso Regression: {}\".format(train_loss3))\n",
    "print(\"Train Loss for Elastic_Net Regression: {}\".format(train_loss4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss for Linear Regression: 1.744762446460397\n",
      "Test Loss for Ridge Regression: 1.7447454967159297\n",
      "Test Loss for Lasso Regression: 2.4785914911596416\n",
      "Test Loss for Elastic_Net Regression: 2.872007197362613\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "y_pred1 = model_lr.predict(X_test)\n",
    "y_pred2 = model_ridge.predict(X_test)\n",
    "y_pred3 = model_lasso.predict(X_test)\n",
    "y_pred4 = model_elasticnet.predict(X_test)\n",
    "\n",
    "\n",
    "test_loss1 = get_rmse(y_test, y_pred1)\n",
    "test_loss2 = get_rmse(y_test, y_pred2)\n",
    "test_loss3 = get_rmse(y_test, y_pred3)\n",
    "test_loss4 = get_rmse(y_test, y_pred4)\n",
    "\n",
    "print(\"Test Loss for Linear Regression: {}\".format(test_loss1))\n",
    "print(\"Test Loss for Ridge Regression: {}\".format(test_loss2))\n",
    "print(\"Test Loss for Lasso Regression: {}\".format(test_loss3))\n",
    "print(\"Test Loss for Elastic_Net Regression: {}\".format(test_loss4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { \n",
    "    'booster': 'gbtree',\n",
    "    'objective':'reg:linear',\n",
    "    'learning_rate': 0.2,\n",
    "    'n_estimators': 200,\n",
    "    'objective': 'reg:linear',  \n",
    "    'gamma': 0.3,                  # control pruning\n",
    "    'max_depth':5 ,               \n",
    "    'lambda': 2,                   # L2 parameter\n",
    "    'subsample': 0.8,              # random sample \n",
    "    'colsample_bytree': 0.7,       # col sample when generate tree\n",
    "    'min_child_weight': 1,\n",
    "    'silent': 0,\n",
    "    'reg_alpha': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:19:05] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.7, gamma=0.3,\n",
       "             importance_type='gain', learning_rate=0.2, max_delta_step=0,\n",
       "             max_depth=5, min_child_weight=1, missing=None, n_estimators=200,\n",
       "             n_jobs=-1, nthread=None, objective='reg:linear', random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None, silent=0,\n",
       "             subsample=0.8, verbosity=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgboost = xgb.XGBRegressor(\n",
    "        learning_rate=params['learning_rate'],\n",
    "        n_estimators=params['n_estimators'],\n",
    "        booster=params['booster'],\n",
    "        objective=params['objective'],\n",
    "        n_jobs=-1,\n",
    "        subsample=params['subsample'],\n",
    "        colsample_bytree=params['colsample_bytree'],\n",
    "        random_state=0,\n",
    "        silent=params['silent'],\n",
    "        max_depth=params['max_depth'],\n",
    "        gamma=params['gamma'],\n",
    "        min_child_weight=params['min_child_weight'],\n",
    "        reg_alpha=params['reg_alpha']\n",
    "    )\n",
    "\n",
    "model_xgboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4578622049332328\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "y_pred = model_xgboost.predict(X_train)\n",
    "train_loss = get_rmse(y_train, y_pred)\n",
    "print(\"Train Loss: {}\".format(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.4535733578299626\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "y_pred = model_xgboost.predict(X_test)\n",
    "test_loss = get_rmse(y_test, y_pred)\n",
    "print(\"Test Loss: {}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Parameters for Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=100 ..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=100, total=  27.2s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=100 ..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   27.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=100, total=  28.3s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=100, total=  27.2s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=100, total=  26.2s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=100, total=  26.6s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=200, total=  48.8s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=200, total=  55.5s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=200, total=  45.6s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=200, total=  51.2s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=200, total=  49.8s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=100, total=  23.3s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=100, total=  22.1s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=100, total=  22.0s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=100, total=  25.1s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=100, total=  26.3s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=200, total=  53.2s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=200, total=  45.6s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=200, total=  43.8s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=200, total=  43.7s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=200, total=  49.1s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=100, total=  22.6s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=100, total=  25.7s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=100, total=  25.6s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=100, total=  26.2s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=100, total=  21.8s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=200, total=  52.0s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=200, total=  44.6s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=200, total=  52.8s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=200, total=  51.8s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=200, total=  50.4s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=100, total=  22.0s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=100, total=  21.8s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=100, total=  21.9s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=100, total=  24.8s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=100, total=  21.8s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=200, total=  50.4s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=200, total=  46.4s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=200, total=  43.7s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=200, total=  44.4s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=200, total=  42.5s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=300 ....................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=100, total=  25.6s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=100, total=  22.1s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=100, total=  26.1s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=100, total=  22.8s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=100, total=  23.7s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=200, total=  44.5s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=200, total=  43.7s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=200, total=  50.5s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=200, total=  45.6s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=200, total=  43.4s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=100, total=  22.3s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=100, total=  22.3s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=100, total=  22.2s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=100, total=  24.8s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=100, total=  25.2s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=200, total=  43.8s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=200, total=  49.5s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=200, total=  46.2s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=200, total=  49.1s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=200, total=  51.3s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=100, total=  21.8s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=100, total=  22.5s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=100, total=  26.5s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=100, total=  21.4s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=100, total=  21.7s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=200, total=  43.4s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=200, total=  44.7s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=200, total=  51.7s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=200, total=  43.6s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=200, total=  42.5s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=100, total=  26.3s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=100, total=  26.3s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=100, total=  25.7s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=100, total=  21.5s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=100, total=  21.6s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=200, total=  51.9s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=200, total=  43.8s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=200, total=  51.4s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=200, total=  44.5s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=200, total=  42.6s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=300 ..................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=100, total=  22.4s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=100, total=  22.1s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=100, total=  22.0s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=100, total=  25.9s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=100, total=  21.6s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=200, total=  43.7s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=200, total=  51.1s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=200, total=  52.6s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=200, total=  50.5s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=200, total=  43.0s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=100, total=  21.9s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=100, total=  22.2s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=100, total=  21.8s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=100, total=  25.6s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=100, total=  25.2s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=200, total=  43.3s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=200, total=  43.3s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=200, total=  51.5s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=200, total=  43.5s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=200, total=  43.2s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=100, total=  22.6s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=100, total=  26.3s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=100, total=  22.2s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=100, total=  22.3s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=100, total=  26.0s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=200, total=  43.7s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=200, total=  43.8s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=200, total=  43.9s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=200, total=  49.5s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=200, total=  51.4s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=100, total=  25.8s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=100, total=  24.6s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=100, total=  22.0s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=100, total=  25.6s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=100, total=  21.6s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=200, total=  43.8s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=200, total=  43.7s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=200, total=  50.6s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=200, total=  43.1s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=200, total=  42.9s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=300 ....................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=100, total=  23.2s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=100, total=  25.8s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=100, total=  26.1s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=100, total=  21.4s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=100, total=  21.8s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=200, total=  48.3s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=200, total=  44.9s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=200, total=  49.5s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=200, total=  52.7s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=200, total=  42.6s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=100, total=  26.3s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=100, total=  21.9s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=100, total=  22.0s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=100, total=  21.7s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=100, total=  22.9s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=200, total=  43.8s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=200, total=  46.5s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=200, total=  43.7s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=200, total=  50.2s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=200, total=  42.8s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=100, total=  24.5s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=100, total=  22.6s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=100, total=  26.5s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=100, total=  21.8s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=100, total=  26.4s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=200, total=  43.7s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=200, total=  49.5s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=200, total=  44.1s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=200, total=  45.2s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=200, total=  49.4s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=300, total= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 225 out of 225 | elapsed: 176.6min finished\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'grid_scores_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a67fce1ee9ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'grid_scores_'"
     ]
    }
   ],
   "source": [
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "        'booster': 'gbtree',\n",
    "        'objective':'reg:squarederror',\n",
    "        'max_depth': 5,\n",
    "        'lambda': 2,                   # L2 parameter\n",
    "        'subsample': 0.8,              # random sample\n",
    "        'colsample_bytree': 0.7,       # col sample when generate tree\n",
    "        'min_child_weight': 1,\n",
    "        'reg_alpha': 0,\n",
    "        'verbosity':1\n",
    "    }\n",
    "\n",
    "search_params={\n",
    "        'learning_rate': [0.1, 0.2, 0.3],\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "    }\n",
    "\n",
    "model_xgboost = xgb.XGBRegressor(\n",
    "        booster=params['booster'],\n",
    "        objective=params['objective'],\n",
    "        n_jobs=-1,\n",
    "        subsample=params['subsample'],\n",
    "        colsample_bytree=params['colsample_bytree'],\n",
    "        random_state=0,\n",
    "        max_depth=params['max_depth'],\n",
    "        min_child_weight=params['min_child_weight'],\n",
    "        reg_alpha=params['reg_alpha'],\n",
    "        verbosity=params['verbosity']\n",
    "    )\n",
    "\n",
    "cv_folders = 5\n",
    "gs = GridSearchCV(model_xgboost, search_params, scoring=\"neg_mean_absolute_error\", cv=cv_folders, verbose=2)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_scorer(mean_absolute_error, greater_is_better=False) XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=0.7, gamma=5,\n",
      "             importance_type='gain', learning_rate=0.2, max_delta_step=0,\n",
      "             max_depth=5, min_child_weight=1, missing=None, n_estimators=300,\n",
      "             n_jobs=-1, nthread=None, objective='reg:squarederror',\n",
      "             random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "             seed=None, silent=None, subsample=0.8, verbosity=1) {'gamma': 5, 'learning_rate': 0.2, 'n_estimators': 300} -0.795759010535048\n"
     ]
    }
   ],
   "source": [
    "print(gs.scorer_, gs.best_estimator_, gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zachguan/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/zachguan/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    4.8s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    7.2s finished\n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestRegressor(n_jobs=-1, max_depth=10, verbose=True).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.1s remaining:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.519465388207335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "y_pred = model_rf.predict(X_train)\n",
    "train_loss = get_rmse(y_train, y_pred)\n",
    "print(\"Train Loss: {}\".format(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.5216837393167282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "y_pred = model_rf.predict(X_test)\n",
    "test_loss = get_rmse(y_test, y_pred)\n",
    "print(\"Test Loss: {}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zachguan/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1          65.7238            1.63m\n",
      "         2          56.2108            1.58m\n",
      "         3          48.4159            1.52m\n",
      "         4          42.0633            1.51m\n",
      "         5          36.8935            1.50m\n",
      "         6          32.6818            1.47m\n",
      "         7          29.1248            1.45m\n",
      "         8          26.1859            1.43m\n",
      "         9          23.6727            1.43m\n",
      "        10          21.4780            1.41m\n",
      "        20          10.9473            1.20m\n",
      "        30           7.8073           59.98s\n",
      "        40           6.4758           49.73s\n",
      "        50           5.6147           41.03s\n",
      "        60           4.9283           32.33s\n",
      "        70           4.3693           24.03s\n",
      "        80           3.8991           15.90s\n",
      "        90           3.5239            7.93s\n",
      "       100           3.2567            0.00s\n"
     ]
    }
   ],
   "source": [
    "model_gb = GradientBoostingRegressor(verbose=True).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.804635711888146\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "y_pred = model_gb.predict(X_train)\n",
    "train_loss = get_rmse(y_train, y_pred)\n",
    "print(\"Train Loss: {}\".format(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.7724299167621504\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "y_pred = model_gb.predict(X_test)\n",
    "test_loss = get_rmse(y_test, y_pred)\n",
    "print(\"Test Loss: {}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn = models.Sequential()\n",
    "model_nn.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model_nn.add(BatchNormalization())\n",
    "model_nn.add(Dense(64, activation='relu'))\n",
    "model_nn.add(BatchNormalization())\n",
    "model_nn.add(Dense(32, activation='relu'))\n",
    "model_nn.add(BatchNormalization())\n",
    "model_nn.add(Dense(8, activation='relu'))\n",
    "model_nn.add(BatchNormalization())\n",
    "model_nn.add(Dense(1))\n",
    "\n",
    "optimizer = optimizers.Adam(lr=1e-3)\n",
    "model_nn.compile(loss='mse', optimizer=optimizer, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               1920      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 13,457\n",
      "Trainable params: 12,993\n",
      "Non-trainable params: 464\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 956868 samples, validate on 239217 samples\n",
      "Epoch 1/10\n",
      "956868/956868 [==============================] - 57s 59us/sample - loss: 34.8917 - mae: 3.4984 - val_loss: 4.4016 - val_mae: 1.5278\n",
      "Epoch 2/10\n",
      "956868/956868 [==============================] - 55s 58us/sample - loss: 2.9957 - mae: 1.0432 - val_loss: 2.5195 - val_mae: 0.9612\n",
      "Epoch 3/10\n",
      "956868/956868 [==============================] - 54s 57us/sample - loss: 2.9051 - mae: 1.0226 - val_loss: 2.9534 - val_mae: 1.0554\n",
      "Epoch 4/10\n",
      "956868/956868 [==============================] - 55s 57us/sample - loss: 2.8560 - mae: 1.0113 - val_loss: 3.0756 - val_mae: 1.1568\n",
      "Epoch 5/10\n",
      "956868/956868 [==============================] - 55s 57us/sample - loss: 2.8209 - mae: 1.0018 - val_loss: 4.5903 - val_mae: 1.5597\n",
      "Epoch 6/10\n",
      "956868/956868 [==============================] - 54s 57us/sample - loss: 2.7952 - mae: 0.9981 - val_loss: 2.2816 - val_mae: 0.8482\n",
      "Epoch 7/10\n",
      "956868/956868 [==============================] - 54s 57us/sample - loss: 2.7695 - mae: 0.9902 - val_loss: 2.4327 - val_mae: 0.9441\n",
      "Epoch 8/10\n",
      "956868/956868 [==============================] - 55s 58us/sample - loss: 2.7409 - mae: 0.9813 - val_loss: 2.8111 - val_mae: 1.0800\n",
      "Epoch 9/10\n",
      "956868/956868 [==============================] - 57s 59us/sample - loss: 2.7246 - mae: 0.9767 - val_loss: 2.3085 - val_mae: 0.8341\n",
      "Epoch 10/10\n",
      "956868/956868 [==============================] - 54s 56us/sample - loss: 2.7094 - mae: 0.9755 - val_loss: 2.3124 - val_mae: 0.8440\n"
     ]
    }
   ],
   "source": [
    "history = model_nn.fit(\n",
    "                x=X_train,\n",
    "                y=y_train,\n",
    "                validation_data=(X_test, y_test), \n",
    "                batch_size=256,\n",
    "                epochs=10,\n",
    "                shuffle=True,\n",
    "                verbose=1\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "epochs = np.arange(len(train_loss))\n",
    "\n",
    "plt.plot(epochs, train_loss, 'r')\n",
    "plt.plot(epochs, test_loss, 'b')\n",
    "plt.legend(['Train Loss', 'Test Loss'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
