{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import math\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, optimizers\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = math.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_csv(path):\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(956868, 239217)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = './data/train.csv'\n",
    "test_path = './data/test.csv'\n",
    "\n",
    "X_train, X_test = read_from_csv(train_path, ), read_from_csv(test_path)\n",
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = pd.DataFrame(X_train['duration']), pd.DataFrame(X_test['duration'])\n",
    "\n",
    "X_train.drop(columns=['duration'], inplace=True)\n",
    "X_test.drop(columns=['duration'], inplace=True)\n",
    "\n",
    "# drop the datetime type columns\n",
    "X_train.drop(columns=['tpep_dropoff_datetime', 'tpep_pickup_datetime'], inplace=True)\n",
    "X_test.drop(columns=['tpep_dropoff_datetime', 'tpep_pickup_datetime'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LinearRegression().fit(X_train, y_train)\n",
    "model_ridge = Ridge().fit(X_train, y_train)\n",
    "model_lasso = Lasso().fit(X_train, y_train)\n",
    "model_elasticnet = ElasticNet().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss for Linear Regression: 1.7834776609741771\n",
      "Train Loss for Ridge Regression: 1.783531230312074\n",
      "Train Loss for Lasso Regression: 2.5064942394275147\n",
      "Train Loss for Elastic_Net Regression: 2.898159245422226\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "y_pred1 = prediction(model_lr, X_train)\n",
    "y_pred2 = prediction(model_ridge, X_train)\n",
    "y_pred3 = prediction(model_lasso, X_train)\n",
    "y_pred4 = prediction(model_elasticnet, X_train)\n",
    "\n",
    "train_loss1 = get_rmse(y_train, y_pred1)\n",
    "train_loss2 = get_rmse(y_train, y_pred2)\n",
    "train_loss3 = get_rmse(y_train, y_pred3)\n",
    "train_loss4 = get_rmse(y_train, y_pred4)\n",
    "\n",
    "print(\"Train Loss for Linear Regression: {}\".format(train_loss1))\n",
    "print(\"Train Loss for Ridge Regression: {}\".format(train_loss2))\n",
    "print(\"Train Loss for Lasso Regression: {}\".format(train_loss3))\n",
    "print(\"Train Loss for Elastic_Net Regression: {}\".format(train_loss4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss for Linear Regression: 1.744762446460397\n",
      "Test Loss for Ridge Regression: 1.7447454967159297\n",
      "Test Loss for Lasso Regression: 2.4785914911596416\n",
      "Test Loss for Elastic_Net Regression: 2.872007197362613\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "y_pred1 = prediction(model_lr, X_test)\n",
    "y_pred2 = prediction(model_ridge, X_test)\n",
    "y_pred3 = prediction(model_lasso, X_test)\n",
    "y_pred4 = prediction(model_elasticnet, X_test)\n",
    "\n",
    "test_loss1 = get_rmse(y_test, y_pred1)\n",
    "test_loss2 = get_rmse(y_test, y_pred2)\n",
    "test_loss3 = get_rmse(y_test, y_pred3)\n",
    "test_loss4 = get_rmse(y_test, y_pred4)\n",
    "\n",
    "print(\"Test Loss for Linear Regression: {}\".format(test_loss1))\n",
    "print(\"Test Loss for Ridge Regression: {}\".format(test_loss2))\n",
    "print(\"Test Loss for Lasso Regression: {}\".format(test_loss3))\n",
    "print(\"Test Loss for Elastic_Net Regression: {}\".format(test_loss4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { \n",
    "    'booster': 'gbtree',\n",
    "    'objective':'reg:linear',\n",
    "    'learning_rate': 0.2,\n",
    "    'n_estimators': 200,\n",
    "    'objective': 'reg:linear',  \n",
    "    'gamma': 0.3,                  # control pruning\n",
    "    'max_depth':5 ,               \n",
    "    'lambda': 2,                   # L2 parameter\n",
    "    'subsample': 0.8,              # random sample \n",
    "    'colsample_bytree': 0.7,       # col sample when generate tree\n",
    "    'min_child_weight': 1,\n",
    "    'silent': 0,\n",
    "    'reg_alpha': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(\n",
    "        learning_rate=params['learning_rate'],\n",
    "        n_estimators=params['n_estimators'],\n",
    "        booster=params['booster'],\n",
    "        objective=params['objective'],\n",
    "        n_jobs=-1,\n",
    "        subsample=params['subsample'],\n",
    "        colsample_bytree=params['colsample_bytree'],\n",
    "        random_state=0,\n",
    "        silent=params['silent'],\n",
    "        max_depth=params['max_depth'],\n",
    "        gamma=params['gamma'],\n",
    "        min_child_weight=params['min_child_weight'],\n",
    "        reg_alpha=params['reg_alpha']\n",
    "    )\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4578622049332328\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "y_pred = model.predict(X_train)\n",
    "\n",
    "train_loss = get_rmse(y_train, y_pred)\n",
    "print(\"Train Loss: {}\".format(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.4535733578299626\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "test_loss = get_rmse(y_test, y_pred)\n",
    "print(\"Test Loss: {}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Parameter for Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=100 ..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=100, total= 1.3min\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=100 ..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=100, total= 1.3min\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=100, total= 1.2min\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=100, total= 1.2min\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=100 ..................\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-872a78c33dc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mcv_folders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"neg_mean_absolute_error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv_folders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1004\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    394\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "        'booster': 'gbtree',\n",
    "        'objective':'reg:squarederror',\n",
    "        'max_depth': 5,\n",
    "        'lambda': 2,                   # L2 parameter\\n\",\n",
    "        'subsample': 0.8,              # random sample \\n\",\n",
    "        'colsample_bytree': 0.7,       # col sample when generate tree\\n\",\n",
    "        'min_child_weight': 1,\n",
    "        'reg_alpha': 0,\n",
    "        'verbosity':1\n",
    "        }\n",
    "search_params={\n",
    "        'learning_rate': [0.1, 0.2, 0.3],\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "}\n",
    "model = xgb.XGBRegressor(\n",
    "        booster=params['booster'],\n",
    "        objective=params['objective'],\n",
    "        n_jobs=-1,\n",
    "        subsample=params['subsample'],\n",
    "        colsample_bytree=params['colsample_bytree'],\n",
    "        random_state=0,\n",
    "        max_depth=params['max_depth'],\n",
    "        min_child_weight=params['min_child_weight'],\n",
    "        reg_alpha=params['reg_alpha'],\n",
    "        verbosity=params['verbosity']\n",
    "    )\n",
    "\n",
    "cv_folders = 5\n",
    "gs = GridSearchCV(model, search_params, scoring=\"neg_mean_absolute_error\", cv=cv_folders, verbose=2)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.grid_scores_, gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zachguan/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/zachguan/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    4.7s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    7.1s finished\n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestRegressor(n_jobs=-1, max_depth=10, verbose=True).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5200744770103742\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "y_pred = prediction(model_rf, X_train)\n",
    "\n",
    "train_loss = get_rmse(y_train, y_pred)\n",
    "print(\"Train Loss: {}\".format(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.5273254216585341\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "y_pred = prediction(model_rf, X_test)\n",
    "\n",
    "test_loss = get_rmse(y_test, y_pred)\n",
    "print(\"Test Loss: {}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zachguan/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1          65.7238            1.68m\n",
      "         2          56.2108            1.55m\n",
      "         3          48.4159            1.52m\n",
      "         4          42.0633            1.48m\n",
      "         5          36.8935            1.47m\n",
      "         6          32.6818            1.45m\n",
      "         7          29.1248            1.44m\n",
      "         8          26.1859            1.42m\n",
      "         9          23.6727            1.42m\n",
      "        10          21.4780            1.40m\n",
      "        20          10.9473            1.22m\n",
      "        30           7.8073            1.02m\n",
      "        40           6.4758           50.45s\n",
      "        50           5.6147           41.87s\n",
      "        60           4.9283           33.14s\n",
      "        70           4.3693           24.68s\n",
      "        80           3.8991           16.35s\n",
      "        90           3.5239            8.14s\n",
      "       100           3.2567            0.00s\n"
     ]
    }
   ],
   "source": [
    "model_gb = GradientBoostingRegressor(verbose=True).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8046357118881458\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "y_pred = prediction(model_gb, X_train)\n",
    "\n",
    "train_loss = get_rmse(y_train, y_pred)\n",
    "print(\"Train Loss: {}\".format(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.7724299167621502\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "y_pred = prediction(model_gb, X_test)\n",
    "\n",
    "test_loss = get_rmse(y_test, y_pred)\n",
    "print(\"Test Loss: {}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn = models.Sequential()\n",
    "model_nn.add(Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model_nn.add(BatchNormalization())\n",
    "model_nn.add(Dense(128, activation='relu'))\n",
    "model_nn.add(BatchNormalization())\n",
    "model_nn.add(Dense(64, activation='relu'))\n",
    "model_nn.add(BatchNormalization())\n",
    "model_nn.add(Dense(32, activation='relu'))\n",
    "model_nn.add(BatchNormalization())\n",
    "model_nn.add(Dense(8, activation='relu'))\n",
    "model_nn.add(BatchNormalization())\n",
    "model_nn.add(Dense(1))\n",
    "\n",
    "optimizer = optimizers.Adam(lr=1e-4)\n",
    "model_nn.compile(loss='mse', optimizer=optimizer, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_39 (Dense)             (None, 256)               3840      \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 49,297\n",
      "Trainable params: 48,321\n",
      "Non-trainable params: 976\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 956868 samples, validate on 239217 samples\n",
      "Epoch 1/20\n",
      "956868/956868 [==============================] - 57s 59us/sample - loss: 230.6187 - mae: 14.4162 - val_loss: 214.8208 - val_mae: 14.3211\n",
      "Epoch 2/20\n",
      "956868/956868 [==============================] - 54s 56us/sample - loss: 169.3922 - mae: 12.7820 - val_loss: 145.8420 - val_mae: 11.9619\n",
      "Epoch 3/20\n",
      "956868/956868 [==============================] - 55s 57us/sample - loss: 116.2642 - mae: 10.6140 - val_loss: 91.2925 - val_mae: 9.4335\n",
      "Epoch 4/20\n",
      "956868/956868 [==============================] - 54s 56us/sample - loss: 66.9726 - mae: 7.9651 - val_loss: 43.3302 - val_mae: 6.4105\n",
      "Epoch 5/20\n",
      "956868/956868 [==============================] - 53s 55us/sample - loss: 29.1274 - mae: 5.0722 - val_loss: 15.5662 - val_mae: 3.6623\n",
      "Epoch 6/20\n",
      "956868/956868 [==============================] - 52s 55us/sample - loss: 8.6002 - mae: 2.4167 - val_loss: 2.8310 - val_mae: 1.0664\n",
      "Epoch 7/20\n",
      "956868/956868 [==============================] - 52s 55us/sample - loss: 3.0629 - mae: 1.0777 - val_loss: 2.4077 - val_mae: 0.9155\n",
      "Epoch 8/20\n",
      "956868/956868 [==============================] - 52s 55us/sample - loss: 2.6741 - mae: 0.9513 - val_loss: 2.3285 - val_mae: 0.8736\n",
      "Epoch 9/20\n",
      "956868/956868 [==============================] - 52s 55us/sample - loss: 2.6518 - mae: 0.9478 - val_loss: 2.6283 - val_mae: 0.9550\n",
      "Epoch 10/20\n",
      "956868/956868 [==============================] - 52s 55us/sample - loss: 2.6144 - mae: 0.9393 - val_loss: 2.2554 - val_mae: 0.8499\n",
      "Epoch 11/20\n",
      "956868/956868 [==============================] - 53s 55us/sample - loss: 2.6024 - mae: 0.9363 - val_loss: 2.2819 - val_mae: 0.8505\n",
      "Epoch 12/20\n",
      "956868/956868 [==============================] - 53s 55us/sample - loss: 2.5741 - mae: 0.9268 - val_loss: 2.3877 - val_mae: 0.9057\n",
      "Epoch 13/20\n",
      "956868/956868 [==============================] - 53s 55us/sample - loss: 2.5514 - mae: 0.9235 - val_loss: 2.2001 - val_mae: 0.8187\n",
      "Epoch 14/20\n",
      "956868/956868 [==============================] - 53s 55us/sample - loss: 2.5371 - mae: 0.9168 - val_loss: 2.3016 - val_mae: 0.8730\n",
      "Epoch 15/20\n",
      "956868/956868 [==============================] - 52s 55us/sample - loss: 2.5367 - mae: 0.9170 - val_loss: 2.2103 - val_mae: 0.8156\n",
      "Epoch 16/20\n",
      "956868/956868 [==============================] - 52s 55us/sample - loss: 2.5317 - mae: 0.9170 - val_loss: 2.5379 - val_mae: 0.9510\n",
      "Epoch 17/20\n",
      "956868/956868 [==============================] - 53s 55us/sample - loss: 2.5220 - mae: 0.9136 - val_loss: 2.1769 - val_mae: 0.8014\n",
      "Epoch 18/20\n",
      "956868/956868 [==============================] - 53s 55us/sample - loss: 2.5103 - mae: 0.9098 - val_loss: 2.2066 - val_mae: 0.8231\n",
      "Epoch 19/20\n",
      "956868/956868 [==============================] - 53s 55us/sample - loss: 2.5044 - mae: 0.9083 - val_loss: 2.2569 - val_mae: 0.8334\n",
      "Epoch 20/20\n",
      "956868/956868 [==============================] - 53s 55us/sample - loss: 2.5016 - mae: 0.9096 - val_loss: 2.6097 - val_mae: 0.9945\n"
     ]
    }
   ],
   "source": [
    "history = model_nn.fit(x=X_train,\n",
    "                    y=y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test), \n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "epochs = np.arange(len(train_loss))\n",
    "plt.plot(epochs, train_loss, 'r')\n",
    "plt.plot(epochs, test_loss, 'b')\n",
    "plt.legend(['Train Loss', 'Test Loss'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model_nn.predict(X_test, batch_size=128, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
