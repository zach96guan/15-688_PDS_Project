{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import math\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, optimizers\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_csv(path):\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = math.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(956868, 239217)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = './data/train.csv'\n",
    "test_path = './data/test.csv'\n",
    "\n",
    "X_train, X_test = read_from_csv(train_path, ), read_from_csv(test_path)\n",
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = pd.DataFrame(X_train['duration']), pd.DataFrame(X_test['duration'])\n",
    "\n",
    "X_train.drop(columns=['duration'], inplace=True)\n",
    "X_test.drop(columns=['duration'], inplace=True)\n",
    "\n",
    "# drop the datetime type columns\n",
    "X_train.drop(columns=['tpep_dropoff_datetime', 'tpep_pickup_datetime'], inplace=True)\n",
    "X_test.drop(columns=['tpep_dropoff_datetime', 'tpep_pickup_datetime'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LinearRegression().fit(X_train, y_train)\n",
    "model_ridge = Ridge().fit(X_train, y_train)\n",
    "model_lasso = Lasso().fit(X_train, y_train)\n",
    "model_elasticnet = ElasticNet().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss for Linear Regression: 1.7834776609741771\n",
      "Train Loss for Ridge Regression: 1.783531230312074\n",
      "Train Loss for Lasso Regression: 2.5064942394275147\n",
      "Train Loss for Elastic_Net Regression: 2.898159245422226\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "y_pred1 = model_lr.predict(X_train)\n",
    "y_pred2 = model_ridge.predict(X_train)\n",
    "y_pred3 = model_lasso.predict(X_train)\n",
    "y_pred4 = model_elasticnet.predict(X_train)\n",
    "\n",
    "train_loss1 = get_rmse(y_train, y_pred1)\n",
    "train_loss2 = get_rmse(y_train, y_pred2)\n",
    "train_loss3 = get_rmse(y_train, y_pred3)\n",
    "train_loss4 = get_rmse(y_train, y_pred4)\n",
    "\n",
    "print(\"Train Loss for Linear Regression: {}\".format(train_loss1))\n",
    "print(\"Train Loss for Ridge Regression: {}\".format(train_loss2))\n",
    "print(\"Train Loss for Lasso Regression: {}\".format(train_loss3))\n",
    "print(\"Train Loss for Elastic_Net Regression: {}\".format(train_loss4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss for Linear Regression: 1.744762446460397\n",
      "Test Loss for Ridge Regression: 1.7447454967159297\n",
      "Test Loss for Lasso Regression: 2.4785914911596416\n",
      "Test Loss for Elastic_Net Regression: 2.872007197362613\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "y_pred1 = model_lr.predict(X_test)\n",
    "y_pred2 = model_ridge.predict(X_test)\n",
    "y_pred3 = model_lasso.predict(X_test)\n",
    "y_pred4 = model_elasticnet.predict(X_test)\n",
    "\n",
    "\n",
    "test_loss1 = get_rmse(y_test, y_pred1)\n",
    "test_loss2 = get_rmse(y_test, y_pred2)\n",
    "test_loss3 = get_rmse(y_test, y_pred3)\n",
    "test_loss4 = get_rmse(y_test, y_pred4)\n",
    "\n",
    "print(\"Test Loss for Linear Regression: {}\".format(test_loss1))\n",
    "print(\"Test Loss for Ridge Regression: {}\".format(test_loss2))\n",
    "print(\"Test Loss for Lasso Regression: {}\".format(test_loss3))\n",
    "print(\"Test Loss for Elastic_Net Regression: {}\".format(test_loss4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { \n",
    "    'booster': 'gbtree',\n",
    "    'objective':'reg:linear',\n",
    "    'learning_rate': 0.2,\n",
    "    'n_estimators': 200,\n",
    "    'objective': 'reg:linear',  \n",
    "    'gamma': 0.3,                  # control pruning\n",
    "    'max_depth':5 ,               \n",
    "    'lambda': 2,                   # L2 parameter\n",
    "    'subsample': 0.8,              # random sample \n",
    "    'colsample_bytree': 0.7,       # col sample when generate tree\n",
    "    'min_child_weight': 1,\n",
    "    'silent': 0,\n",
    "    'reg_alpha': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:19:05] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.7, gamma=0.3,\n",
       "             importance_type='gain', learning_rate=0.2, max_delta_step=0,\n",
       "             max_depth=5, min_child_weight=1, missing=None, n_estimators=200,\n",
       "             n_jobs=-1, nthread=None, objective='reg:linear', random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None, silent=0,\n",
       "             subsample=0.8, verbosity=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgboost = xgb.XGBRegressor(\n",
    "        learning_rate=params['learning_rate'],\n",
    "        n_estimators=params['n_estimators'],\n",
    "        booster=params['booster'],\n",
    "        objective=params['objective'],\n",
    "        n_jobs=-1,\n",
    "        subsample=params['subsample'],\n",
    "        colsample_bytree=params['colsample_bytree'],\n",
    "        random_state=0,\n",
    "        silent=params['silent'],\n",
    "        max_depth=params['max_depth'],\n",
    "        gamma=params['gamma'],\n",
    "        min_child_weight=params['min_child_weight'],\n",
    "        reg_alpha=params['reg_alpha']\n",
    "    )\n",
    "\n",
    "model_xgboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4578622049332328\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "y_pred = model_xgboost.predict(X_train)\n",
    "train_loss = get_rmse(y_train, y_pred)\n",
    "print(\"Train Loss: {}\".format(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.4535733578299626\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "y_pred = model_xgboost.predict(X_test)\n",
    "test_loss = get_rmse(y_test, y_pred)\n",
    "print(\"Test Loss: {}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Parameters for Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=100 ..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=100, total=  27.2s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=100 ..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   27.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=100, total=  28.3s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=100, total=  27.2s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=100, total=  26.2s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=100, total=  26.6s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=200, total=  48.8s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=200, total=  55.5s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=200, total=  45.6s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=200, total=  51.2s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=200, total=  49.8s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=100, total=  23.3s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=100, total=  22.1s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=100, total=  22.0s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=100, total=  25.1s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=100, total=  26.3s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=200, total=  53.2s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=200, total=  45.6s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=200, total=  43.8s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=200, total=  43.7s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=200, total=  49.1s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=100, total=  22.6s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=100, total=  25.7s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=100, total=  25.6s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=100, total=  26.2s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=100, total=  21.8s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=200, total=  52.0s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=200, total=  44.6s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=200, total=  52.8s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=200, total=  51.8s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=200, total=  50.4s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=100, total=  22.0s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=100, total=  21.8s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=100, total=  21.9s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=100, total=  24.8s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=100, total=  21.8s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=200, total=  50.4s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=200, total=  46.4s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=200, total=  43.7s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=200, total=  44.4s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=200, total=  42.5s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=300 ....................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=100, total=  25.6s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=100, total=  22.1s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=100, total=  26.1s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=100, total=  22.8s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=100, total=  23.7s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=200, total=  44.5s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=200, total=  43.7s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=200, total=  50.5s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=200, total=  45.6s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=200, total=  43.4s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=100, total=  22.3s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=100, total=  22.3s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=100, total=  22.2s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=100, total=  24.8s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=100, total=  25.2s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=200, total=  43.8s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=200, total=  49.5s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=200, total=  46.2s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=200, total=  49.1s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=200, total=  51.3s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=100, total=  21.8s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=100, total=  22.5s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=100, total=  26.5s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=100, total=  21.4s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=100, total=  21.7s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=200, total=  43.4s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=200, total=  44.7s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=200, total=  51.7s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=200, total=  43.6s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=200, total=  42.5s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=100, total=  26.3s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=100, total=  26.3s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=100, total=  25.7s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=100, total=  21.5s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=100, total=  21.6s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=200, total=  51.9s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=200, total=  43.8s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=200, total=  51.4s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=200, total=  44.5s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=200, total=  42.6s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=300 ..................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=100, total=  22.4s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=100, total=  22.1s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=100, total=  22.0s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=100, total=  25.9s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=100, total=  21.6s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=200, total=  43.7s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=200, total=  51.1s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=200, total=  52.6s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=200, total=  50.5s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=200, total=  43.0s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=100, total=  21.9s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=100, total=  22.2s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=100, total=  21.8s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=100, total=  25.6s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=100, total=  25.2s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=200, total=  43.3s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=200, total=  43.3s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=200, total=  51.5s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=200, total=  43.5s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=200, total=  43.2s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=100, total=  22.6s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=100, total=  26.3s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=100, total=  22.2s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=100, total=  22.3s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=100, total=  26.0s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=200, total=  43.7s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=200, total=  43.8s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=200, total=  43.9s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=200, total=  49.5s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=200, total=  51.4s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=100, total=  25.8s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=100, total=  24.6s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=100, total=  22.0s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=100, total=  25.6s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=100, total=  21.6s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=200, total=  43.8s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=200, total=  43.7s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=200, total=  50.6s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=200, total=  43.1s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=200, total=  42.9s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=300 ....................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=100, total=  23.2s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=100, total=  25.8s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=100, total=  26.1s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=100, total=  21.4s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=100, total=  21.8s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=200, total=  48.3s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=200, total=  44.9s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=200, total=  49.5s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=200, total=  52.7s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=200, total=  42.6s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=100, total=  26.3s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=100, total=  21.9s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=100, total=  22.0s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=100, total=  21.7s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=100, total=  22.9s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=200, total=  43.8s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=200, total=  46.5s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=200, total=  43.7s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=200, total=  50.2s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=200, total=  42.8s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=100, total=  24.5s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=100, total=  22.6s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=100, total=  26.5s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=100, total=  21.8s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=100, total=  26.4s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=200, total=  43.7s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=200, total=  49.5s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=200, total=  44.1s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=200, total=  45.2s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=200, total=  49.4s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=300, total= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 225 out of 225 | elapsed: 176.6min finished\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'grid_scores_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a67fce1ee9ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'grid_scores_'"
     ]
    }
   ],
   "source": [
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "        'booster': 'gbtree',\n",
    "        'objective':'reg:squarederror',\n",
    "        'max_depth': 5,\n",
    "        'lambda': 2,                   # L2 parameter\n",
    "        'subsample': 0.8,              # random sample\n",
    "        'colsample_bytree': 0.7,       # col sample when generate tree\n",
    "        'min_child_weight': 1,\n",
    "        'reg_alpha': 0,\n",
    "        'verbosity':1\n",
    "    }\n",
    "\n",
    "search_params={\n",
    "        'learning_rate': [0.1, 0.2, 0.3],\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "    }\n",
    "\n",
    "model_xgboost = xgb.XGBRegressor(\n",
    "        booster=params['booster'],\n",
    "        objective=params['objective'],\n",
    "        n_jobs=-1,\n",
    "        subsample=params['subsample'],\n",
    "        colsample_bytree=params['colsample_bytree'],\n",
    "        random_state=0,\n",
    "        max_depth=params['max_depth'],\n",
    "        min_child_weight=params['min_child_weight'],\n",
    "        reg_alpha=params['reg_alpha'],\n",
    "        verbosity=params['verbosity']\n",
    "    )\n",
    "\n",
    "cv_folders = 5\n",
    "gs = GridSearchCV(model_xgboost, search_params, scoring=\"neg_mean_absolute_error\", cv=cv_folders, verbose=2)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_scorer(mean_absolute_error, greater_is_better=False) XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=0.7, gamma=5,\n",
      "             importance_type='gain', learning_rate=0.2, max_delta_step=0,\n",
      "             max_depth=5, min_child_weight=1, missing=None, n_estimators=300,\n",
      "             n_jobs=-1, nthread=None, objective='reg:squarederror',\n",
      "             random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "             seed=None, silent=None, subsample=0.8, verbosity=1) {'gamma': 5, 'learning_rate': 0.2, 'n_estimators': 300} -0.795759010535048\n"
     ]
    }
   ],
   "source": [
    "print(gs.scorer_, gs.best_estimator_, gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.7, gamma=5,\n",
       "             importance_type='gain', learning_rate=0.2, max_delta_step=0,\n",
       "             max_depth=5, min_child_weight=1, missing=None, n_estimators=300,\n",
       "             n_jobs=-1, nthread=None, objective='reg:squarederror',\n",
       "             random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "             seed=None, silent=None, subsample=0.8, verbosity=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best model: gs.best_estimator_\n",
    "best_xgboost = xgb.XGBRegressor(\n",
    "                base_score=0.5,\n",
    "                booster='gbtree',\n",
    "                colsample_bylevel=1,\n",
    "                colsample_bynode=1,\n",
    "                colsample_bytree=0.7,\n",
    "                gamma=5,\n",
    "                importance_type='gain',\n",
    "                learning_rate=0.2,\n",
    "                max_delta_step=0,\n",
    "                max_depth=5,\n",
    "                min_child_weight=1,\n",
    "                missing=None,\n",
    "                n_estimators=300,\n",
    "                n_jobs=-1,\n",
    "                nthread=None,\n",
    "                objective='reg:squarederror',\n",
    "                random_state=0,\n",
    "                reg_alpha=0,\n",
    "                reg_lambda=1,\n",
    "                scale_pos_weight=1,\n",
    "                seed=None,\n",
    "                silent=None,\n",
    "                subsample=0.8,\n",
    "                verbosity=1\n",
    "            )\n",
    "\n",
    "best_xgboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00754438 0.02380871 0.40642664 0.00352404 0.00248134 0.00098796\n",
      " 0.062282   0.00515633 0.         0.01846733 0.0273641  0.3797335\n",
      " 0.0590335  0.00319011]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a511f5ed0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(best_xgboost.feature_importances_)\n",
    "\n",
    "xgb.plot_importance(best_xgboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zachguan/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/zachguan/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    4.8s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    7.2s finished\n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestRegressor(n_jobs=-1, max_depth=10, verbose=True).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.1s remaining:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.519465388207335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "y_pred = model_rf.predict(X_train)\n",
    "train_loss = get_rmse(y_train, y_pred)\n",
    "print(\"Train Loss: {}\".format(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.5216837393167282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "y_pred = model_rf.predict(X_test)\n",
    "test_loss = get_rmse(y_test, y_pred)\n",
    "print(\"Test Loss: {}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zachguan/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1          65.7238            1.63m\n",
      "         2          56.2108            1.58m\n",
      "         3          48.4159            1.52m\n",
      "         4          42.0633            1.51m\n",
      "         5          36.8935            1.50m\n",
      "         6          32.6818            1.47m\n",
      "         7          29.1248            1.45m\n",
      "         8          26.1859            1.43m\n",
      "         9          23.6727            1.43m\n",
      "        10          21.4780            1.41m\n",
      "        20          10.9473            1.20m\n",
      "        30           7.8073           59.98s\n",
      "        40           6.4758           49.73s\n",
      "        50           5.6147           41.03s\n",
      "        60           4.9283           32.33s\n",
      "        70           4.3693           24.03s\n",
      "        80           3.8991           15.90s\n",
      "        90           3.5239            7.93s\n",
      "       100           3.2567            0.00s\n"
     ]
    }
   ],
   "source": [
    "model_gb = GradientBoostingRegressor(verbose=True).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.804635711888146\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "y_pred = model_gb.predict(X_train)\n",
    "train_loss = get_rmse(y_train, y_pred)\n",
    "print(\"Train Loss: {}\".format(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.7724299167621504\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "y_pred = model_gb.predict(X_test)\n",
    "test_loss = get_rmse(y_test, y_pred)\n",
    "print(\"Test Loss: {}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn = models.Sequential()\n",
    "model_nn.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model_nn.add(BatchNormalization())\n",
    "model_nn.add(Dense(64, activation='relu'))\n",
    "model_nn.add(BatchNormalization())\n",
    "model_nn.add(Dense(32, activation='relu'))\n",
    "model_nn.add(BatchNormalization())\n",
    "model_nn.add(Dense(8, activation='relu'))\n",
    "model_nn.add(BatchNormalization())\n",
    "model_nn.add(Dense(1))\n",
    "\n",
    "optimizer = optimizers.Adam(lr=1e-3)\n",
    "model_nn.compile(loss='mse', optimizer=optimizer, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               1920      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 13,457\n",
      "Trainable params: 12,993\n",
      "Non-trainable params: 464\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 956868 samples, validate on 239217 samples\n",
      "Epoch 1/10\n",
      "956868/956868 [==============================] - 57s 59us/sample - loss: 34.8917 - mae: 3.4984 - val_loss: 4.4016 - val_mae: 1.5278\n",
      "Epoch 2/10\n",
      "956868/956868 [==============================] - 55s 58us/sample - loss: 2.9957 - mae: 1.0432 - val_loss: 2.5195 - val_mae: 0.9612\n",
      "Epoch 3/10\n",
      "956868/956868 [==============================] - 54s 57us/sample - loss: 2.9051 - mae: 1.0226 - val_loss: 2.9534 - val_mae: 1.0554\n",
      "Epoch 4/10\n",
      "956868/956868 [==============================] - 55s 57us/sample - loss: 2.8560 - mae: 1.0113 - val_loss: 3.0756 - val_mae: 1.1568\n",
      "Epoch 5/10\n",
      "956868/956868 [==============================] - 55s 57us/sample - loss: 2.8209 - mae: 1.0018 - val_loss: 4.5903 - val_mae: 1.5597\n",
      "Epoch 6/10\n",
      "956868/956868 [==============================] - 54s 57us/sample - loss: 2.7952 - mae: 0.9981 - val_loss: 2.2816 - val_mae: 0.8482\n",
      "Epoch 7/10\n",
      "956868/956868 [==============================] - 54s 57us/sample - loss: 2.7695 - mae: 0.9902 - val_loss: 2.4327 - val_mae: 0.9441\n",
      "Epoch 8/10\n",
      "956868/956868 [==============================] - 55s 58us/sample - loss: 2.7409 - mae: 0.9813 - val_loss: 2.8111 - val_mae: 1.0800\n",
      "Epoch 9/10\n",
      "956868/956868 [==============================] - 57s 59us/sample - loss: 2.7246 - mae: 0.9767 - val_loss: 2.3085 - val_mae: 0.8341\n",
      "Epoch 10/10\n",
      "956868/956868 [==============================] - 54s 56us/sample - loss: 2.7094 - mae: 0.9755 - val_loss: 2.3124 - val_mae: 0.8440\n"
     ]
    }
   ],
   "source": [
    "history = model_nn.fit(\n",
    "                x=X_train,\n",
    "                y=y_train,\n",
    "                validation_data=(X_test, y_test), \n",
    "                batch_size=256,\n",
    "                epochs=10,\n",
    "                shuffle=True,\n",
    "                verbose=1\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "epochs = np.arange(len(train_loss))\n",
    "\n",
    "plt.plot(epochs, train_loss, 'r')\n",
    "plt.plot(epochs, test_loss, 'b')\n",
    "plt.legend(['Train Loss', 'Test Loss'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
