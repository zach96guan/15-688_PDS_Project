{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import math\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, optimizers\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from yellowbrick.regressor import ResidualsPlot\n",
    "\n",
    "import seaborn as sns;\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_csv(path):\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = pd.DataFrame(X_train['duration']), pd.DataFrame(X_test['duration'])\n",
    "\n",
    "X_train.drop(columns=['duration'], inplace=True)\n",
    "X_test.drop(columns=['duration'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(956868, 239217)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = './data/train.csv'\n",
    "test_path = './data/test.csv'\n",
    "\n",
    "X_train, X_test = read_from_csv(train_path, ), read_from_csv(test_path)\n",
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = math.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model \n",
    "\n",
    "Our task is building regression model to predict duration of trip. We use linear regression model as our baseline model. To capture the non-linear relationship between features and target, we further use XgBoost, Gradient Boost, Random Forest and Nerual Network model for prediction. We conduct parameter searching and tuning for those models to get best results. We use root mean square error as valuation metric. Finally, we will compare and analysis among different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For linear regression model, we chose for different variation. The simplest version of linear model shows as follow:\n",
    "$$ \\hat y = w_{1}x_{1} + w_{1}x_{1} + ... w_{n}x_{n} + b $$\n",
    "The cost function is:\n",
    "$$ \\sum_{i=1}^{N} (y_{i} - w_{i}^{T} \\times x_{i}) $$\n",
    "\n",
    "For Ridge regression, the cost function consists of loss and regularization part. Regularization part equals to square of the magnitude of the coefficients:\n",
    "$$ \\sum_{i=1}^{N} (y_{i} - w_{i}^{T} \\times x_{i}) + \\lambda \\sum_{j=0}^{F}w_{j}^{2}$$\n",
    "\n",
    "For Lasso regression, regularization part of cost function is sum of absolute value of weights. This L1 regularization can shrink and completely neglect some of the features:\n",
    "$$ \\sum_{i=1}^{N} (y_{i} - w_{i}^{T} \\times x_{i}) + \\lambda \\sum_{j=0}^{F}|w_{j}|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LinearRegression().fit(X_train, y_train)\n",
    "model_ridge = Ridge().fit(X_train, y_train)\n",
    "model_lasso = Lasso().fit(X_train, y_train)\n",
    "model_elasticnet = ElasticNet().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss for Linear Regression: 3.7733229022723593\n",
      "Train Loss for Ridge Regression: 3.7733229022723593\n",
      "Train Loss for Lasso Regression: 3.8977648979870616\n",
      "Train Loss for Elastic_Net Regression: 3.8645430555151363\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "y_pred1 = model_lr.predict(X_train)\n",
    "y_pred2 = model_ridge.predict(X_train)\n",
    "y_pred3 = model_lasso.predict(X_train)\n",
    "y_pred4 = model_elasticnet.predict(X_train)\n",
    "\n",
    "train_loss1 = get_rmse(y_train, y_pred1)\n",
    "train_loss2 = get_rmse(y_train, y_pred2)\n",
    "train_loss3 = get_rmse(y_train, y_pred3)\n",
    "train_loss4 = get_rmse(y_train, y_pred4)\n",
    "\n",
    "print(\"Train Loss for Linear Regression: {}\".format(train_loss1))\n",
    "print(\"Train Loss for Ridge Regression: {}\".format(train_loss2))\n",
    "print(\"Train Loss for Lasso Regression: {}\".format(train_loss3))\n",
    "print(\"Train Loss for Elastic_Net Regression: {}\".format(train_loss4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss for Linear Regression: 1.744762446460397\n",
      "Test Loss for Ridge Regression: 1.7447454967159297\n",
      "Test Loss for Lasso Regression: 2.4785914911596416\n",
      "Test Loss for Elastic_Net Regression: 2.872007197362613\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "y_pred1 = model_lr.predict(X_test)\n",
    "y_pred2 = model_ridge.predict(X_test)\n",
    "y_pred3 = model_lasso.predict(X_test)\n",
    "y_pred4 = model_elasticnet.predict(X_test)\n",
    "\n",
    "\n",
    "test_loss1 = get_rmse(y_test, y_pred1)\n",
    "test_loss2 = get_rmse(y_test, y_pred2)\n",
    "test_loss3 = get_rmse(y_test, y_pred3)\n",
    "test_loss4 = get_rmse(y_test, y_pred4)\n",
    "\n",
    "print(\"Test Loss for Linear Regression: {}\".format(test_loss1))\n",
    "print(\"Test Loss for Ridge Regression: {}\".format(test_loss2))\n",
    "print(\"Test Loss for Lasso Regression: {}\".format(test_loss3))\n",
    "print(\"Test Loss for Elastic_Net Regression: {}\".format(test_loss4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { \n",
    "    'booster': 'gbtree',\n",
    "    'objective':'reg:linear',\n",
    "    'learning_rate': 0.2,\n",
    "    'n_estimators': 200,\n",
    "    'objective': 'reg:linear',  \n",
    "    'gamma': 0.3,                  # control pruning\n",
    "    'max_depth':5 ,               \n",
    "    'lambda': 2,                   # L2 parameter\n",
    "    'subsample': 0.8,              # random sample \n",
    "    'colsample_bytree': 0.7,       # col sample when generate tree\n",
    "    'min_child_weight': 1,\n",
    "    'silent': 0,\n",
    "    'reg_alpha': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:19:05] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.7, gamma=0.3,\n",
       "             importance_type='gain', learning_rate=0.2, max_delta_step=0,\n",
       "             max_depth=5, min_child_weight=1, missing=None, n_estimators=200,\n",
       "             n_jobs=-1, nthread=None, objective='reg:linear', random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None, silent=0,\n",
       "             subsample=0.8, verbosity=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgboost = xgb.XGBRegressor(\n",
    "        learning_rate=params['learning_rate'],\n",
    "        n_estimators=params['n_estimators'],\n",
    "        booster=params['booster'],\n",
    "        objective=params['objective'],\n",
    "        n_jobs=-1,\n",
    "        subsample=params['subsample'],\n",
    "        colsample_bytree=params['colsample_bytree'],\n",
    "        random_state=0,\n",
    "        silent=params['silent'],\n",
    "        max_depth=params['max_depth'],\n",
    "        gamma=params['gamma'],\n",
    "        min_child_weight=params['min_child_weight'],\n",
    "        reg_alpha=params['reg_alpha']\n",
    "    )\n",
    "\n",
    "model_xgboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4578622049332328\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "y_pred = model_xgboost.predict(X_train)\n",
    "train_loss = get_rmse(y_train, y_pred)\n",
    "print(\"Train Loss: {}\".format(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.4535733578299626\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "y_pred = model_xgboost.predict(X_test)\n",
    "test_loss = get_rmse(y_test, y_pred)\n",
    "print(\"Test Loss: {}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Parameters for Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=100 ..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=100, total=  27.2s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=100 ..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   27.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=100, total=  28.3s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=100, total=  27.2s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=100, total=  26.2s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=100, total=  26.6s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=200, total=  48.8s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=200, total=  55.5s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=200, total=  45.6s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=200, total=  51.2s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=200, total=  49.8s\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=0.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=100, total=  23.3s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=100, total=  22.1s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=100, total=  22.0s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=100, total=  25.1s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=100, total=  26.3s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=200, total=  53.2s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=200, total=  45.6s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=200, total=  43.8s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=200, total=  43.7s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=200, total=  49.1s\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=0.5, learning_rate=0.2, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=100, total=  22.6s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=100, total=  25.7s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=100, total=  25.6s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=100, total=  26.2s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=100, total=  21.8s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=200, total=  52.0s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=200, total=  44.6s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=200, total=  52.8s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=200, total=  51.8s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=200, total=  50.4s\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=0.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=0.5, learning_rate=0.3, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=100, total=  22.0s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=100, total=  21.8s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=100, total=  21.9s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=100, total=  24.8s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=100, total=  21.8s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=200, total=  50.4s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=200, total=  46.4s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=200, total=  43.7s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=200, total=  44.4s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=200, total=  42.5s\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.1, n_estimators=300 ....................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... gamma=1, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=100, total=  25.6s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=100, total=  22.1s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=100, total=  26.1s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=100, total=  22.8s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=100, total=  23.7s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=200, total=  44.5s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=200, total=  43.7s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=200, total=  50.5s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=200, total=  45.6s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=200, total=  43.4s\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.2, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=100, total=  22.3s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=100, total=  22.3s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=100, total=  22.2s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=100, total=  24.8s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=100, total=  25.2s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=200, total=  43.8s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=200, total=  49.5s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=200, total=  46.2s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=200, total=  49.1s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=200, total=  51.3s\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=1, learning_rate=0.3, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=100, total=  21.8s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=100, total=  22.5s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=100, total=  26.5s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=100, total=  21.4s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=100, total=  21.7s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=200, total=  43.4s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=200, total=  44.7s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=200, total=  51.7s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=200, total=  43.6s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=200, total=  42.5s\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1.5, learning_rate=0.1, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.1, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=100, total=  26.3s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=100, total=  26.3s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=100, total=  25.7s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=100, total=  21.5s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=100, total=  21.6s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=200, total=  51.9s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=200, total=  43.8s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=200, total=  51.4s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=200, total=  44.5s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=200, total=  42.6s\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=300 ..................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1.5, learning_rate=0.2, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=100, total=  22.4s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=100, total=  22.1s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=100, total=  22.0s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=100, total=  25.9s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=100 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=100, total=  21.6s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=200, total=  43.7s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=200, total=  51.1s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=200, total=  52.6s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=200, total=  50.5s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=200 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=200, total=  43.0s\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=1.5, learning_rate=0.3, n_estimators=300 ..................\n",
      "[CV] ... gamma=1.5, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=100, total=  21.9s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=100, total=  22.2s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=100, total=  21.8s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=100, total=  25.6s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=100, total=  25.2s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=200, total=  43.3s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=200, total=  43.3s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=200, total=  51.5s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=200, total=  43.5s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=200, total=  43.2s\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=2, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.1, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=100, total=  22.6s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=100, total=  26.3s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=100, total=  22.2s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=100, total=  22.3s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=100, total=  26.0s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=200, total=  43.7s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=200, total=  43.8s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=200, total=  43.9s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=200, total=  49.5s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=200, total=  51.4s\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=2, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=100, total=  25.8s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=100, total=  24.6s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=100, total=  22.0s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=100, total=  25.6s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=100, total=  21.6s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=200, total=  43.8s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=200, total=  43.7s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=200, total=  50.6s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=200, total=  43.1s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=200, total=  42.9s\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=300 ....................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=2, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=2, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=100, total=  23.2s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=100, total=  25.8s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=100, total=  26.1s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=100, total=  21.4s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=100, total=  21.8s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=200, total=  48.3s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=200, total=  44.9s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=200, total=  49.5s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=200, total=  52.7s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=200, total=  42.6s\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=5, learning_rate=0.1, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.1, n_estimators=300, total= 1.2min\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=100, total=  26.3s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=100, total=  21.9s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=100, total=  22.0s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=100, total=  21.7s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=100, total=  22.9s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=200, total=  43.8s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=200, total=  46.5s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=200, total=  43.7s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=200, total=  50.2s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=200, total=  42.8s\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=5, learning_rate=0.2, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.2, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=100, total=  24.5s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=100, total=  22.6s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=100, total=  26.5s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=100, total=  21.8s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=100 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=100, total=  26.4s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=200, total=  43.7s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=200, total=  49.5s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=200, total=  44.1s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=200, total=  45.2s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=200 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=200, total=  49.4s\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=300, total= 1.3min\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=300, total= 1.1min\n",
      "[CV] gamma=5, learning_rate=0.3, n_estimators=300 ....................\n",
      "[CV] ..... gamma=5, learning_rate=0.3, n_estimators=300, total= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 225 out of 225 | elapsed: 176.6min finished\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'grid_scores_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a67fce1ee9ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'grid_scores_'"
     ]
    }
   ],
   "source": [
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "        'booster': 'gbtree',\n",
    "        'objective':'reg:squarederror',\n",
    "        'max_depth': 5,\n",
    "        'lambda': 2,                   # L2 parameter\n",
    "        'subsample': 0.8,              # random sample\n",
    "        'colsample_bytree': 0.7,       # col sample when generate tree\n",
    "        'min_child_weight': 1,\n",
    "        'reg_alpha': 0,\n",
    "        'verbosity':1\n",
    "    }\n",
    "\n",
    "search_params={\n",
    "        'learning_rate': [0.1, 0.2, 0.3],\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "    }\n",
    "\n",
    "model_xgboost = xgb.XGBRegressor(\n",
    "        booster=params['booster'],\n",
    "        objective=params['objective'],\n",
    "        n_jobs=-1,\n",
    "        subsample=params['subsample'],\n",
    "        colsample_bytree=params['colsample_bytree'],\n",
    "        random_state=0,\n",
    "        max_depth=params['max_depth'],\n",
    "        min_child_weight=params['min_child_weight'],\n",
    "        reg_alpha=params['reg_alpha'],\n",
    "        verbosity=params['verbosity']\n",
    "    )\n",
    "\n",
    "cv_folders = 5\n",
    "gs = GridSearchCV(model_xgboost, search_params, scoring=\"neg_mean_absolute_error\", cv=cv_folders, verbose=2)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_scorer(mean_absolute_error, greater_is_better=False) XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=0.7, gamma=5,\n",
      "             importance_type='gain', learning_rate=0.2, max_delta_step=0,\n",
      "             max_depth=5, min_child_weight=1, missing=None, n_estimators=300,\n",
      "             n_jobs=-1, nthread=None, objective='reg:squarederror',\n",
      "             random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "             seed=None, silent=None, subsample=0.8, verbosity=1) {'gamma': 5, 'learning_rate': 0.2, 'n_estimators': 300} -0.795759010535048\n"
     ]
    }
   ],
   "source": [
    "print(gs.scorer_, gs.best_estimator_, gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.7, gamma=5,\n",
       "             importance_type='gain', learning_rate=0.2, max_delta_step=0,\n",
       "             max_depth=5, min_child_weight=1, missing=None, n_estimators=300,\n",
       "             n_jobs=-1, nthread=None, objective='reg:squarederror',\n",
       "             random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "             seed=None, silent=None, subsample=0.8, verbosity=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best model: gs.best_estimator_\n",
    "best_xgboost = xgb.XGBRegressor(\n",
    "                base_score=0.5,\n",
    "                booster='gbtree',\n",
    "                colsample_bylevel=1,\n",
    "                colsample_bynode=1,\n",
    "                colsample_bytree=0.7,\n",
    "                gamma=5,\n",
    "                importance_type='gain',\n",
    "                learning_rate=0.2,\n",
    "                max_delta_step=0,\n",
    "                max_depth=5,\n",
    "                min_child_weight=1,\n",
    "                missing=None,\n",
    "                n_estimators=300,\n",
    "                n_jobs=-1,\n",
    "                nthread=None,\n",
    "                objective='reg:squarederror',\n",
    "                random_state=0,\n",
    "                reg_alpha=0,\n",
    "                reg_lambda=1,\n",
    "                scale_pos_weight=1,\n",
    "                seed=None,\n",
    "                silent=None,\n",
    "                subsample=0.8,\n",
    "                verbosity=1\n",
    "            )\n",
    "\n",
    "best_xgboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00754438 0.02380871 0.40642664 0.00352404 0.00248134 0.00098796\n",
      " 0.062282   0.00515633 0.         0.01846733 0.0273641  0.3797335\n",
      " 0.0590335  0.00319011]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a511f5ed0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(best_xgboost.feature_importances_)\n",
    "\n",
    "xgb.plot_importance(best_xgboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zachguan/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/zachguan/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    4.8s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    7.2s finished\n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestRegressor(n_jobs=-1, max_depth=10, verbose=True).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.1s remaining:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.519465388207335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "y_pred = model_rf.predict(X_train)\n",
    "train_loss = get_rmse(y_train, y_pred)\n",
    "print(\"Train Loss: {}\".format(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.5216837393167282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "y_pred = model_rf.predict(X_test)\n",
    "test_loss = get_rmse(y_test, y_pred)\n",
    "print(\"Test Loss: {}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zachguan/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1          65.7238            1.63m\n",
      "         2          56.2108            1.58m\n",
      "         3          48.4159            1.52m\n",
      "         4          42.0633            1.51m\n",
      "         5          36.8935            1.50m\n",
      "         6          32.6818            1.47m\n",
      "         7          29.1248            1.45m\n",
      "         8          26.1859            1.43m\n",
      "         9          23.6727            1.43m\n",
      "        10          21.4780            1.41m\n",
      "        20          10.9473            1.20m\n",
      "        30           7.8073           59.98s\n",
      "        40           6.4758           49.73s\n",
      "        50           5.6147           41.03s\n",
      "        60           4.9283           32.33s\n",
      "        70           4.3693           24.03s\n",
      "        80           3.8991           15.90s\n",
      "        90           3.5239            7.93s\n",
      "       100           3.2567            0.00s\n"
     ]
    }
   ],
   "source": [
    "model_gb = GradientBoostingRegressor(verbose=True).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.804635711888146\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "y_pred = model_gb.predict(X_train)\n",
    "train_loss = get_rmse(y_train, y_pred)\n",
    "print(\"Train Loss: {}\".format(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.7724299167621504\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "y_pred = model_gb.predict(X_test)\n",
    "test_loss = get_rmse(y_test, y_pred)\n",
    "print(\"Test Loss: {}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn = models.Sequential()\n",
    "model_nn.add(Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model_nn.add(BatchNormalization())\n",
    "model_nn.add(Dense(128, activation='relu'))\n",
    "model_nn.add(BatchNormalization())\n",
    "model_nn.add(Dense(64, activation='relu'))\n",
    "model_nn.add(BatchNormalization())\n",
    "model_nn.add(Dense(32, activation='relu'))\n",
    "model_nn.add(BatchNormalization())\n",
    "model_nn.add(Dense(8, activation='relu'))\n",
    "model_nn.add(BatchNormalization())\n",
    "model_nn.add(Dense(1))\n",
    "\n",
    "optimizer = optimizers.Adam(lr=1e-4)\n",
    "model_nn.compile(loss='mse', optimizer=optimizer, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 256)               3840      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 49,297\n",
      "Trainable params: 48,321\n",
      "Non-trainable params: 976\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 956868 samples, validate on 239217 samples\n",
      "Epoch 1/8\n",
      "956868/956868 [==============================] - 83s 87us/sample - loss: 203.3254 - mae: 13.6804 - val_loss: 146.8639 - val_mae: 12.0161\n",
      "Epoch 2/8\n",
      "956868/956868 [==============================] - 83s 87us/sample - loss: 96.5020 - mae: 9.5391 - val_loss: 39.6142 - val_mae: 6.1050\n",
      "Epoch 3/8\n",
      "956868/956868 [==============================] - 82s 86us/sample - loss: 21.5197 - mae: 4.0537 - val_loss: 4.9232 - val_mae: 1.6031\n",
      "Epoch 4/8\n",
      "956868/956868 [==============================] - 84s 88us/sample - loss: 3.2159 - mae: 1.1143 - val_loss: 2.5453 - val_mae: 0.9139\n",
      "Epoch 5/8\n",
      "956868/956868 [==============================] - 83s 87us/sample - loss: 2.8501 - mae: 1.0086 - val_loss: 2.3179 - val_mae: 0.8553\n",
      "Epoch 6/8\n",
      "956868/956868 [==============================] - 79s 83us/sample - loss: 2.8054 - mae: 1.0014 - val_loss: 2.2782 - val_mae: 0.8391\n",
      "Epoch 7/8\n",
      "956868/956868 [==============================] - 80s 83us/sample - loss: 2.7820 - mae: 0.9978 - val_loss: 2.2290 - val_mae: 0.8188\n",
      "Epoch 8/8\n",
      "956868/956868 [==============================] - 81s 84us/sample - loss: 2.7646 - mae: 0.9923 - val_loss: 2.7496 - val_mae: 1.0540\n"
     ]
    }
   ],
   "source": [
    "history = model_nn.fit(\n",
    "                x=X_train,\n",
    "                y=y_train,\n",
    "                validation_data=(X_test, y_test), \n",
    "                batch_size=256,\n",
    "                epochs=8,\n",
    "                shuffle=True,\n",
    "                verbose=1\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "epochs = np.arange(len(train_loss))\n",
    "\n",
    "plt.plot(epochs, train_loss, 'r')\n",
    "plt.plot(epochs, test_loss, 'b')\n",
    "plt.legend(['Train Loss', 'Test Loss'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
